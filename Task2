1.numpy和pytorch实现梯度下降法
2.设定初始值
3.求取梯度
4.在梯度方向上进行参数的更新
5.numpy和pytorch实现线性回归
6.pytorch实现一个简单的神经网络



梯度下降法的一般步骤：

- 设定初始值

- 求梯度

- 在梯度方向上完成参数的更新




一个神经网络的典型训练过程如下：
定义包含一些可学习参数（或者叫权重）的神经网络
在输入数据集上迭代
通过网络处理输入
计算损失（输出和正确答案的距离）
将梯度反向传播给网络的参数
更新网络的权重，一般使用一个简单的规则：weight = weight - learning_rate * gradient
